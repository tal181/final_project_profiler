#MUST be used for queries using collections `Size` function.Without it, the default behaviour is to consider nulls as collections with -1 values :) See https://spark.apache.org/docs/3.0.1/api/sql/index.html#size
spark.sql.legacy.sizeOfNull false
spark.sql.sources.partitionOverwriteMode dynamic
spark.metrics.appStatusSource.enabled true
spark.hadoop.javax.jdo.option.ConnectionDriverName org.mariadb.jdbc.Driver
spark.sql.parquet.mergeSchema false
spark.serializer org.apache.spark.serializer.KryoSerializer
spark.hadoop.fs.s3a.aws.credentials.provider com.amazonaws.auth.DefaultAWSCredentialsProviderChain
mapreduce.fileoutputcommitter.algorithm.version 2
spark.sql.hive.convertMetastoreParquet true
